{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mc_dropout with PICP and MPIW evaluation with variational dropout","version":"0.3.2","provenance":[{"file_id":"15BOiz-F2OI0zeYO2nB0oSFu82vwCZWeN","timestamp":1562771511679},{"file_id":"11wYjIF9_mPTpJJ-M-TqLJ1X6sfeXtrOd","timestamp":1562642625703}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xAYPKSFrG8AF","colab_type":"code","outputId":"9b02a0c5-b4c0-4dd8-e85d-878cf787ad18","executionInfo":{"status":"ok","timestamp":1563010229959,"user_tz":-60,"elapsed":4307,"user":{"displayName":"Maryleen Ndubuaku","photoUrl":"https://lh6.googleusercontent.com/-fRuvMDTZLbM/AAAAAAAAAAI/AAAAAAAABlE/G0jMD35Ag7w/s64/photo.jpg","userId":"17568265093952818562"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["\n","#!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n","#!pip3 install torchvision\n","!pip3 install GPy\n","\n","import pandas as pd\n","import zipfile\n","import urllib.request\n","import os\n","import GPy\n","import time\n","import copy\n","import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.optim import Optimizer\n","from torch.optim.sgd import SGD\n","from sklearn.model_selection import KFold\n","\n","from torchvision import datasets, transforms\n","from torchvision.utils import make_grid\n","from tqdm import tqdm, trange\n","from google.colab import files\n","%config InlineBackend.figure_format = 'svg'\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: GPy in /usr/local/lib/python3.6/dist-packages (1.9.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from GPy) (1.12.0)\n","Requirement already satisfied: paramz>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from GPy) (0.9.5)\n","Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from GPy) (1.3.0)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from GPy) (1.16.4)\n","Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.6/dist-packages (from paramz>=0.9.0->GPy) (4.4.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1-7dNcVmHA3I","colab_type":"code","outputId":"e10efd94-81bf-46eb-ba75-2d7cb8a9891c","executionInfo":{"status":"ok","timestamp":1563010229967,"user_tz":-60,"elapsed":4276,"user":{"displayName":"Maryleen Ndubuaku","photoUrl":"https://lh6.googleusercontent.com/-fRuvMDTZLbM/AAAAAAAAAAI/AAAAAAAABlE/G0jMD35Ag7w/s64/photo.jpg","userId":"17568265093952818562"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch.cuda.device(0)\n","torch.cuda.get_device_name(torch.cuda.current_device())"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"_1S5kt0omQ-N","colab_type":"code","colab":{}},"source":["def to_variable(var=(), cuda=True, volatile=False):\n","    out = []\n","    for i in var:\n","        \n","        if isinstance(i, np.ndarray):\n","            i = torch.from_numpy(i).type(torch.FloatTensor)\n","\n","        if not i.is_cuda and cuda:\n","            i = i.cuda()\n","\n","        if not isinstance(i, Variable):\n","            i = Variable(i, volatile=volatile)\n","\n","        out.append(i)\n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Va8V78eFFsc9","colab_type":"code","colab":{}},"source":["def log_gaussian_loss(output, target, sigma, no_dim):\n","    exponent = -0.5*(target - output)**2/sigma**2\n","    log_coeff = -no_dim*torch.log(sigma) - 0.5*no_dim*np.log(2*np.pi)\n","    \n","    return - (log_coeff + exponent).sum()\n","\n","\n","def get_kl_divergence(weights, prior, varpost):\n","    prior_loglik = prior.loglik(weights)\n","    \n","    varpost_loglik = varpost.loglik(weights)\n","    varpost_lik = varpost_loglik.exp()\n","    \n","    return (varpost_lik*(varpost_loglik - prior_loglik)).sum()\n","\n","\n","class gaussian:\n","    def __init__(self, mu, sigma):\n","        self.mu = mu\n","        self.sigma = sigma\n","        \n","    def loglik(self, weights):\n","        exponent = -0.5*(weights - self.mu)**2/self.sigma**2\n","        log_coeff = -0.5*(np.log(2*np.pi) + 2*np.log(self.sigma))\n","        \n","        return (exponent + log_coeff).sum()\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qrCAId3A1rnC","colab_type":"code","colab":{}},"source":["class VariationalDropout(nn.Module):\n","    def __init__(self, alpha=1.0, dim=None):\n","        super(VariationalDropout, self).__init__()\n","        \n","        self.dim = dim\n","        self.max_alpha = alpha\n","        # Initial alpha\n","        log_alpha = (torch.ones(dim) * alpha).log()\n","        self.log_alpha = nn.Parameter(log_alpha)\n","        \n","    def kl(self):\n","        c1 = 1.16145124\n","        c2 = -1.50204118\n","        c3 = 0.58629921\n","        \n","        alpha = self.log_alpha.exp()\n","        \n","        negative_kl = 0.5 * self.log_alpha + c1 * alpha + c2 * alpha**2 + c3 * alpha**3\n","        \n","        kl = -negative_kl\n","        \n","        return kl.mean()\n","    \n","    def forward(self, x):\n","        \"\"\"\n","        Sample noise   e ~ N(1, alpha)\n","        Multiply noise h = h_ * e\n","        \"\"\"\n","        if self.train():\n","            # N(0,1)\n","            epsilon = Variable(torch.randn(x.size()))\n","            if x.is_cuda:\n","                epsilon = epsilon.cuda()\n","\n","            # Clip alpha\n","            self.log_alpha.data = torch.clamp(self.log_alpha.data, max=self.max_alpha)\n","            alpha = self.log_alpha.exp()\n","\n","            # N(1, alpha)\n","            epsilon = epsilon * alpha\n","\n","            return x * epsilon\n","        else:\n","            return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eS38UCO9B41k","colab_type":"code","colab":{}},"source":["\n","class GaussianDropout(nn.Module):\n","    def __init__(self, alpha=1.0):\n","        super(GaussianDropout, self).__init__()\n","        self.alpha = torch.Tensor([alpha])\n","        \n","    def forward(self, x):\n","        \"\"\"\n","        Sample noise   e ~ N(1, alpha)\n","        Multiply noise h = h_ * e\n","        \"\"\"\n","        if self.train():\n","            # N(1, alpha)\n","            epsilon = torch.randn(x.size()) * self.alpha + 1\n","\n","            epsilon = Variable(epsilon)\n","            if x.is_cuda:\n","                epsilon = epsilon.cuda()\n","\n","            return x * epsilon\n","        else:\n","            return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p7Z_M_kG1wfK","colab_type":"code","colab":{}},"source":["def dropout(p=None, dim=None, method='standard'):\n","    if method == 'standard':\n","        return nn.Dropout(p)\n","    elif method == 'gaussian':\n","        return GaussianDropout(p/(1-p))\n","    elif method == 'variational':\n","        return VariationalDropout(p/(1-p), dim)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oAYelw3B5G-K","colab":{}},"source":["class MC_Dropout_Wrapper:\n","    def __init__(self, network, learn_rate, batch_size, weight_decay):\n","        \n","        self.learn_rate = learn_rate\n","        self.batch_size = batch_size\n","        \n","        self.network = network\n","        self.network.cuda()\n","        \n","        self.optimizer = torch.optim.SGD(self.network.parameters(), lr=learn_rate, weight_decay=weight_decay)\n","        self.loss_func = log_gaussian_loss\n","        \n","        self.dropout_method = 'standard'\n","    \n","    def fit(self, x, y):\n","        x, y = to_variable(var=(x, y), cuda=True)\n","        \n","        # reset gradient and total loss\n","        self.optimizer.zero_grad()\n","        \n","        output = self.network(x)\n","        loss = self.loss_func(output[:, :1], y, output[:, 1:].exp(), 1)\n","        \n","        if self.dropout_method == 'variational':\n","            kl = self.network.kl()\n","            total_loss = loss + kl / 10\n","        else:\n","            total_loss = loss\n","            \n","        loss = total_loss    \n","        loss.backward()\n","        self.optimizer.step()\n","\n","        return loss\n","    \n","    def get_loss_and_rmse(self, x, y, num_samples):\n","        x, y = to_variable(var=(x, y), cuda=True)\n","        \n","        means, stds = [], []\n","        for i in range(num_samples):\n","            output = self.network(x)\n","            means.append(output[:, :1])\n","            stds.append(output[:, 1:].exp())\n","        \n","        means, stds = torch.cat(means, dim=1), torch.cat(stds, dim=1)\n","        mean = means.mean(dim=-1)[:, None]\n","        std = ((means.var(dim=-1) + stds.mean(dim=-1)**2)**0.5)[:, None]\n","        loss = self.loss_func(mean, y, std, 1)\n","        \n","        rmse = ((mean - y)**2).mean()**0.5\n","\n","        return loss.detach().cpu(), rmse.detach().cpu(), output   #added output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBBlvk1JylkX","colab_type":"text"},"source":["# UCI datasets"]},{"cell_type":"code","metadata":{"id":"jk3OXX4nzFM5","colab_type":"code","colab":{}},"source":["\n","def evaluation(y_test, test_pred):\n","  \n","  print (test_pred.shape)\n","  test_pred = test_pred.data.cpu().numpy()\n","  mean_np = test_pred.mean(1)\n","  std_np = test_pred.std(1)\n","  print (mean_np.shape)\n","  print (std_np.shape)\n"," \n","   \n","  #calculate the upper and lower bounds of y using 95% prediction interval\n","  \n","  y_u_pred = mean_np + (std_np * 1.96)  #upper 95% limit\n","  y_l_pred = mean_np - (std_np * 1.96)  #lower 95% limit\n","  print (y_u_pred.shape)\n","  print (y_l_pred.shape)\n","    \n","  y_val = y_test\n","  print (y_val.shape)\n","  K_u = y_u_pred > y_val\n","  K_l = y_l_pred < y_val\n","  y_all_cap = K_u * K_l\n","\n","  #calculate PICP and MPIW\n","  PICP = np.mean(K_u * K_l)\n","  MPIW = np.round(np.mean(y_u_pred - y_l_pred),3)\n","  return PICP, MPIW"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CA4b-sP4eBJw"},"source":["# Housing dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OHCuHqooeBJy","outputId":"371eb251-6281-4fd7-8ace-ba621db6f307","executionInfo":{"status":"ok","timestamp":1563010231679,"user_tz":-60,"elapsed":5939,"user":{"displayName":"Maryleen Ndubuaku","photoUrl":"https://lh6.googleusercontent.com/-fRuvMDTZLbM/AAAAAAAAAAI/AAAAAAAABlE/G0jMD35Ag7w/s64/photo.jpg","userId":"17568265093952818562"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["np.random.seed(0)\n","!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\" --no-check-certificate \n","data = pd.read_csv('housing.data', header=0, delimiter=\"\\s+\").values\n","data = data[np.random.permutation(np.arange(len(data)))]"],"execution_count":10,"outputs":[{"output_type":"stream","text":["--2019-07-13 09:30:32--  https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\n","Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n","Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 49082 (48K) [application/x-httpd-php]\n","Saving to: ‘housing.data.1’\n","\n","\rhousing.data.1        0%[                    ]       0  --.-KB/s               \rhousing.data.1      100%[===================>]  47.93K  --.-KB/s    in 0.06s   \n","\n","2019-07-13 09:30:32 (787 KB/s) - ‘housing.data.1’ saved [49082/49082]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0AmcpT5DDO2d","colab_type":"code","colab":{}},"source":["class MC_Dropout_Model_UCI(nn.Module):\n","    def __init__(self, input_dim, output_dim, num_units, drop_prob):\n","        super(MC_Dropout_Model_UCI, self).__init__()\n","        \n","\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","        self.drop_prob = drop_prob\n","        \n","        '''\n","        # network with two hidden and one output layer\n","        self.layer1 = nn.Linear(input_dim, num_units)\n","        self.layer2 = nn.Linear(num_units, num_units)\n","        self.layer3 = nn.Linear(num_units, 2*output_dim)\n","        '''\n","        \n","        self.activation = nn.ReLU(inplace = True)\n","        self.dropout_method = 'standard'\n","        \n","        self.net = nn.Sequential(\n","            nn.Linear(input_dim, num_units),\n","            dropout(0.2, num_units, self.dropout_method),\n","            nn.ReLU(),                \n","            nn.Linear(num_units, num_units),\n","            dropout(0.5, num_units, self.dropout_method),\n","            nn.ReLU(),                \n","            nn.Linear(num_units, 2*output_dim),              \n","        )\n","    \n","    def kl(self):\n","        kl = 0\n","        for name, module in self.net.named_modules():\n","            if isinstance(module, VariationalDropout):\n","                kl += module.kl().sum()\n","        return kl\n","        \n","            \n","    def forward(self, x):\n","        return self.net(x)\n","\n","\n","def train_mc_dropout(data, drop_prob, n_splits, num_epochs, num_units, learn_rate, weight_decay, log_every, num_samples):\n","    \n","    kf = KFold(n_splits=n_splits)\n","    in_dim = data.shape[1] - 1\n","    train_logliks, test_logliks = [], []\n","    train_rmses, test_rmses = [], []\n","    xtrain_rmse, xtest_rmse = [], []\n","    rmse = []\n","\n","    split = np.random.rand(len(data)) < 0.9\n","\n","    train = data[split]\n","\n","    test = data[~split]#\n","\n","    in_dim = data.shape[1] - 1\n","\n","    x_train, y_train = train[:, :in_dim], train[:, in_dim:]\n","\n","    x_test, y_test = test[:, :in_dim], test[:, in_dim:]\n","\n","    print(x_train.shape)\n","    print(y_train.shape)\n","\n","\n","    x_means, x_stds = x_train.mean(axis = 0), x_train.var(axis = 0)**0.5\n","    y_means, y_stds = y_train.mean(axis = 0), y_train.var(axis = 0)**0.5\n","\n","    x_train = (x_train - x_means)/x_stds\n","    y_train = (y_train - y_means)/y_stds\n","\n","    x_test = (x_test - x_means)/x_stds\n","    y_test = (y_test - y_means)/y_stds\n","    \n","    num_epochs, batch_size = num_epochs, len(x_train)\n","    \n","    net = MC_Dropout_Wrapper(network=MC_Dropout_Model_UCI(input_dim=in_dim, output_dim=1, num_units=num_units, drop_prob=drop_prob),\n","                             learn_rate=learn_rate, batch_size=batch_size, weight_decay=weight_decay)\n","\n","    losses = []\n","    fit_loss_train = np.zeros(num_epochs)\n","\n","    for i in range(num_epochs):\n","        loss = net.fit(x_train, y_train)\n","\n","        if i % log_every == 0 or i == num_epochs - 1:\n","            test_loss, rmse, test_pred = net.get_loss_and_rmse(x_test, y_test, num_samples=num_samples)\n","            test_loss, rmse = test_loss.cpu().data.numpy(), rmse.cpu().data.numpy()\n","\n","            print('Epoch: %4d, Train loss: %6.3f Test loss: %6.3f RMSE: %.3f Num. networks: %2d' %\n","                  (i, loss.cpu().data.numpy()/len(x_train), test_loss/len(x_test), rmse*y_stds[0], len(x_train)))\n","\n","\n","        train_loss, train_rmse, train_pred = net.get_loss_and_rmse(x_train, y_train, num_samples=num_samples)\n","        test_loss, test_rmse, test_pred = net.get_loss_and_rmse(x_test, y_test, num_samples=num_samples)\n","\n","        xtrain_rmse.append(np.asscalar(train_rmse))\n","        xtest_rmse.append(np.asscalar(test_rmse))\n","    \n","    \n","    train_logliks.append((train_loss.cpu().data.numpy()/len(x_train) + np.log(y_stds)[0]))\n","    test_logliks.append((test_loss.cpu().data.numpy()/len(x_test) + np.log(y_stds)[0]))\n","\n","    train_rmses.append(y_stds[0]*train_rmse.cpu().data.numpy())\n","    test_rmses.append(y_stds[0]*test_rmse.cpu().data.numpy())\n","\n","\n","\n","    print('Train log. lik. = %6.3f +/- %6.3f' % (-np.array(train_logliks).mean(), np.array(train_logliks).var()**0.5))\n","    print('Test  log. lik. = %6.3f +/- %6.3f' % (-np.array(test_logliks).mean(), np.array(test_logliks).var()**0.5))\n","    print('Train RMSE      = %6.3f +/- %6.3f' % (np.array(train_rmses).mean(), np.array(train_rmses).var()**0.5))\n","    print('Test  RMSE      = %6.3f +/- %6.3f' % (np.array(test_rmses).mean(), np.array(test_rmses).var()**0.5))\n","    \n","    plt.plot(xtrain_rmse)\n","    plt.plot(xtest_rmse)\n","    plt.show()\n","    \n","    #plt.plot(rmse)\n","    \n","    return x_train, y_train, x_test, y_test, test_pred, net"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXsgiUziqh9w","colab_type":"code","outputId":"d41d5937-31b7-4533-eacc-050145f21e12","executionInfo":{"status":"ok","timestamp":1563010237353,"user_tz":-60,"elapsed":11588,"user":{"displayName":"Maryleen Ndubuaku","photoUrl":"https://lh6.googleusercontent.com/-fRuvMDTZLbM/AAAAAAAAAAI/AAAAAAAABlE/G0jMD35Ag7w/s64/photo.jpg","userId":"17568265093952818562"}},"colab":{"base_uri":"https://localhost:8080/","height":530}},"source":["x_train_housing, y_train_housing, x_test_housing, y_test_housing, test_pred_housing, model_housing = train_mc_dropout(data=data, drop_prob=0.1, num_epochs=100, n_splits=10, num_units=100, learn_rate=1e-4,\n","                       weight_decay=1e-1/len(data)**0.5, num_samples=20, log_every=50)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["(445, 13)\n","(445, 1)\n","Epoch:    0, Train loss:  1.466 Test loss:  1.528 RMSE: 10.594 Num. networks: 445\n","Epoch:   50, Train loss:  0.743 Test loss:  0.717 RMSE: 5.500 Num. networks: 445\n","Epoch:   99, Train loss:  0.544 Test loss:  0.516 RMSE: 4.642 Num. networks: 445\n","Train log. lik. = -2.644 +/-  0.000\n","Test  log. lik. = -2.736 +/-  0.000\n","Train RMSE      =  3.975 +/-  0.000\n","Test  RMSE      =  4.770 +/-  0.000\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"252.018125pt\" version=\"1.1\" viewBox=\"0 0 375.603125 252.018125\" width=\"375.603125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 252.018125 \nL 375.603125 252.018125 \nL 375.603125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 228.14 \nL 364.903125 228.14 \nL 364.903125 10.7 \nL 30.103125 10.7 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"macae953fb7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#macae953fb7\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(42.140057 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"106.80891\" xlink:href=\"#macae953fb7\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(100.44641 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"168.296513\" xlink:href=\"#macae953fb7\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(161.934013 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"229.784117\" xlink:href=\"#macae953fb7\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(223.421617 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"291.27172\" xlink:href=\"#macae953fb7\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(284.90922 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"352.759323\" xlink:href=\"#macae953fb7\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(343.215573 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mf0472a51ba\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf0472a51ba\" y=\"227.972062\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.4 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 231.771281)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf0472a51ba\" y=\"201.054664\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 204.853882)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf0472a51ba\" y=\"174.137265\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 177.936484)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf0472a51ba\" y=\"147.219867\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.7 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(7.2 151.019086)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf0472a51ba\" y=\"120.302468\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 124.101687)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf0472a51ba\" y=\"93.38507\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.9 -->\n      <defs>\n       <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n      </defs>\n      <g transform=\"translate(7.2 97.184289)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf0472a51ba\" y=\"66.467672\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 70.26689)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf0472a51ba\" y=\"39.550273\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.1 -->\n      <g transform=\"translate(7.2 43.349492)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf0472a51ba\" y=\"12.632875\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.2 -->\n      <g transform=\"translate(7.2 16.432094)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p25a6cd57e1)\" d=\"M 45.321307 64.412048 \nL 48.395687 69.778532 \nL 51.470067 74.002072 \nL 54.544447 76.781907 \nL 57.618827 81.450379 \nL 60.693208 86.76809 \nL 63.767588 90.152961 \nL 66.841968 93.985604 \nL 69.916348 97.914399 \nL 72.990728 101.681599 \nL 76.065108 107.208475 \nL 79.139489 110.367527 \nL 82.213869 114.608266 \nL 85.288249 117.30448 \nL 88.362629 124.316663 \nL 91.437009 128.429708 \nL 94.511389 131.082907 \nL 97.58577 135.531336 \nL 100.66015 139.027425 \nL 103.73453 142.873545 \nL 106.80891 144.388149 \nL 109.88329 148.406791 \nL 112.95767 151.021035 \nL 116.032051 151.91212 \nL 119.106431 156.630987 \nL 122.180811 156.053563 \nL 125.255191 158.648603 \nL 128.329571 160.237522 \nL 131.403951 162.347503 \nL 134.478332 167.096533 \nL 137.552712 169.145547 \nL 140.627092 170.701785 \nL 143.701472 175.717675 \nL 146.775852 175.204635 \nL 149.850232 175.839995 \nL 152.924613 179.754094 \nL 155.998993 179.669044 \nL 159.073373 182.81802 \nL 162.147753 181.507673 \nL 165.222133 183.460455 \nL 168.296513 185.591582 \nL 171.370894 186.787487 \nL 174.445274 188.456065 \nL 177.519654 188.642481 \nL 180.594034 187.08443 \nL 183.668414 190.089394 \nL 186.742794 194.749829 \nL 189.817175 192.231993 \nL 192.891555 192.973548 \nL 195.965935 196.478877 \nL 199.040315 195.026781 \nL 202.114695 196.438013 \nL 205.189075 195.724503 \nL 208.263456 198.191239 \nL 211.337836 198.914969 \nL 214.412216 196.383608 \nL 217.486596 199.3694 \nL 220.560976 200.527297 \nL 223.635356 201.603602 \nL 226.709737 202.66801 \nL 229.784117 200.357679 \nL 232.858497 204.804472 \nL 235.932877 205.709676 \nL 239.007257 205.120635 \nL 242.081637 205.246019 \nL 245.156018 204.93365 \nL 248.230398 203.277089 \nL 251.304778 204.189569 \nL 254.379158 206.405954 \nL 257.453538 205.468799 \nL 260.527918 208.907738 \nL 263.602299 205.878098 \nL 266.676679 206.604499 \nL 269.751059 207.461562 \nL 272.825439 207.362619 \nL 275.899819 209.463278 \nL 278.974199 210.766847 \nL 282.04858 210.736074 \nL 285.12296 210.324096 \nL 288.19734 212.17195 \nL 291.27172 212.633376 \nL 294.3461 213.194483 \nL 297.42048 213.964179 \nL 300.494861 212.079288 \nL 303.569241 213.536582 \nL 306.643621 213.412105 \nL 309.718001 216.031539 \nL 312.792381 213.175231 \nL 315.866761 213.484664 \nL 318.941142 214.376134 \nL 322.015522 215.376639 \nL 325.089902 214.747825 \nL 328.164282 216.033232 \nL 331.238662 213.81789 \nL 334.313042 217.684218 \nL 337.387423 217.697751 \nL 340.461803 216.721007 \nL 343.536183 218.256364 \nL 346.610563 218.234271 \nL 349.684943 217.08418 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#p25a6cd57e1)\" d=\"M 45.321307 20.583636 \nL 48.395687 25.271667 \nL 51.470067 33.726095 \nL 54.544447 38.302491 \nL 57.618827 40.709447 \nL 60.693208 45.687168 \nL 63.767588 50.623496 \nL 66.841968 54.731182 \nL 69.916348 60.792196 \nL 72.990728 62.075589 \nL 76.065108 67.851244 \nL 79.139489 74.098576 \nL 82.213869 75.092022 \nL 85.288249 81.867604 \nL 88.362629 86.514241 \nL 91.437009 91.583397 \nL 94.511389 95.005956 \nL 97.58577 102.847855 \nL 100.66015 104.314985 \nL 103.73453 107.001941 \nL 106.80891 107.268416 \nL 109.88329 110.619643 \nL 112.95767 123.191993 \nL 116.032051 122.423805 \nL 119.106431 128.610684 \nL 122.180811 126.340937 \nL 125.255191 130.063182 \nL 128.329571 130.583842 \nL 131.403951 137.804245 \nL 134.478332 140.578978 \nL 137.552712 144.665999 \nL 140.627092 147.69718 \nL 143.701472 149.230747 \nL 146.775852 152.772689 \nL 149.850232 156.266579 \nL 152.924613 157.68532 \nL 155.998993 157.525505 \nL 159.073373 160.482835 \nL 162.147753 157.329351 \nL 165.222133 150.65398 \nL 168.296513 162.23258 \nL 171.370894 165.679429 \nL 174.445274 162.584442 \nL 177.519654 172.12152 \nL 180.594034 169.845323 \nL 183.668414 167.207093 \nL 186.742794 174.822772 \nL 189.817175 175.271491 \nL 192.891555 178.589875 \nL 195.965935 174.579304 \nL 199.040315 171.900947 \nL 202.114695 176.433158 \nL 205.189075 180.870533 \nL 208.263456 179.869627 \nL 211.337836 181.174423 \nL 214.412216 181.802594 \nL 217.486596 181.229807 \nL 220.560976 177.085861 \nL 223.635356 181.660588 \nL 226.709737 184.954297 \nL 229.784117 187.511794 \nL 232.858497 186.608532 \nL 235.932877 187.077418 \nL 239.007257 188.195879 \nL 242.081637 194.528454 \nL 245.156018 183.472985 \nL 248.230398 186.545479 \nL 251.304778 187.702846 \nL 254.379158 188.826666 \nL 257.453538 184.390783 \nL 260.527918 185.610032 \nL 263.602299 190.113974 \nL 266.676679 183.382673 \nL 269.751059 188.633785 \nL 272.825439 193.49108 \nL 275.899819 195.036071 \nL 278.974199 194.736753 \nL 282.04858 189.469229 \nL 285.12296 195.749051 \nL 288.19734 193.545084 \nL 291.27172 191.591002 \nL 294.3461 191.654633 \nL 297.42048 195.940953 \nL 300.494861 200.612202 \nL 303.569241 198.472732 \nL 306.643621 194.195107 \nL 309.718001 193.782792 \nL 312.792381 190.425244 \nL 315.866761 199.279906 \nL 318.941142 194.474129 \nL 322.015522 197.18114 \nL 325.089902 202.592948 \nL 328.164282 197.526632 \nL 331.238662 199.221105 \nL 334.313042 197.289678 \nL 337.387423 192.85787 \nL 340.461803 196.188978 \nL 343.536183 197.699538 \nL 346.610563 196.727014 \nL 349.684943 193.381691 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 228.14 \nL 30.103125 10.7 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 228.14 \nL 364.903125 10.7 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 228.14 \nL 364.903125 228.14 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 10.7 \nL 364.903125 10.7 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p25a6cd57e1\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"10.7\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"HdZW5zfZzTnF","colab_type":"code","outputId":"96dfb780-61b7-422c-976e-192f915bbbaa","executionInfo":{"status":"ok","timestamp":1563010237356,"user_tz":-60,"elapsed":11570,"user":{"displayName":"Maryleen Ndubuaku","photoUrl":"https://lh6.googleusercontent.com/-fRuvMDTZLbM/AAAAAAAAAAI/AAAAAAAABlE/G0jMD35Ag7w/s64/photo.jpg","userId":"17568265093952818562"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["PICP_housing, MPIW_housing = evaluation (y_test_housing, test_pred_housing)\n","print ('PICP: ', PICP_housing)\n","print ('MPIW: ', MPIW_housing)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["torch.Size([60, 2])\n","(60,)\n","(60,)\n","(60,)\n","(60,)\n","(60, 1)\n","PICP:  0.5297222222222222\n","MPIW:  1.815\n"],"name":"stdout"}]}]}